---
id: 20260112162435
title: Disaster Tweets - ベースラインからの改善案
author: takeikumi
type: permanent
form: report
tags: [kaggle, kaggle_disaster_tweets, improvement, strategy, permanent]
links:
  - project_kaggle_disaster_tweets
  - task_disaster_tweets_baseline_submit_20260105120020
  - exp20260106030720_report
  - disaster_tweets_eda_20260105180000
created: 2026-01-12
updated: 2026-01-12
---

# Disaster Tweets - ベースラインからの改善案

#kaggle_disaster_tweets

## 内容

ベースライン実験（exp20260106030720）の結果を踏まえた改善案のまとめ。CV F1=0.7425、Public LB=0.80079を起点に、さらなる性能向上を目指すための具体的な改善方向性を整理する。

## ベースライン結果の振り返り

### 現在の性能
- **CV Mean F1**: 0.7425
- **CV Std F1**: 0.0137（安定している）
- **Train F1**: 0.8542
- **Public LB F1**: **0.80079**

### 観察された問題点
1. **過学習の傾向**: Train F1 (0.8542) > CV F1 (0.7425)
2. **Public LB > CV**: Public LB (0.80079) > CV Mean (0.7425)
   - CVが保守的だった可能性
   - testデータの分布が異なる可能性
3. **特徴量**: textのみ使用（keyword、locationは未使用）

## 改善案（優先順位順）

### 1. 特徴量エンジニアリングの改善

#### 1.1 keyword特徴量の追加
**理由**: EDAでkeywordとtargetの相関が非常に強いことが確認されている
- `debris`=100%災害、`wreckage`=100%災害、`derailment`=100%災害
- `outbreak`=97.5%災害、`oil%20spill`=97.4%災害

**実装案**:
- keywordをカテゴリカル特徴量として追加
- 欠損値処理: 最頻値で補完、または"unknown"として扱う
- エンコーディング: ターゲットエンコーディング、またはワンホットエンコーディング

**期待効果**: CV F1が0.75-0.80程度まで向上する可能性

#### 1.2 前処理の効果確認
**理由**: ベースラインではURL/メンション除去を実施したが、効果が未検証

**実装案**:
- 前処理なしの実験を実施
- URL除去のみ、メンション除去のみの比較実験
- ハッシュタグの活用（現在は除去していないが、特徴量として明示的に扱う）

**期待効果**: 前処理の最適な組み合わせを発見

#### 1.3 特徴量の組み合わせ
**実装案**:
- text + keywordの組み合わせ
- テキスト長、単語数などのメタ特徴量の追加
- ハッシュタグの有無、URLの有無などのバイナリ特徴量

### 2. ハイパーパラメータチューニング

#### 2.1 LogisticRegressionのチューニング
**現在の設定**:
- C: 1.0（デフォルト）
- max_iter: 2000

**改善案**:
- C値のグリッドサーチ: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
- solverの変更: 'lbfgs'（デフォルト）、'liblinear'、'saga'の比較
- クラス重みの調整: `class_weight='balanced'`で不均衡データに対応

**期待効果**: CV F1が0.75-0.77程度まで向上する可能性

#### 2.2 TF-IDFパラメータの調整
**現在の設定**:
- max_features: 20000
- ngram_range: (1, 2)
- min_df: 2

**改善案**:
- max_featuresの調整: [10000, 20000, 30000, 50000]
- ngram_rangeの拡張: (1, 3)の検討（ただし過剰になる可能性）
- min_dfの調整: [1, 2, 3, 5]

### 3. モデルの変更

#### 3.1 より強力な線形モデル
**候補**:
- **LinearSVC**: ロジスティック回帰と似た性能だが、異なる最適化手法
- **RidgeClassifier**: L2正則化付き線形分類器

**期待効果**: わずかな改善（0.01-0.02程度）

#### 3.2 非線形モデル
**候補**:
- **XGBoost**: 勾配ブースティング、非線形な関係を捉えられる
- **LightGBM**: XGBoostより高速、メモリ効率が良い
- **CatBoost**: カテゴリカル特徴量に強い

**期待効果**: CV F1が0.80-0.85程度まで向上する可能性

**実装時の注意**:
- カテゴリカル特徴量（keyword）を直接扱える
- ハイパーパラメータチューニングが必要
- 学習時間が長くなる可能性

#### 3.3 深層学習モデル
**候補**:
- **LSTM/GRU**: テキストの順序情報を考慮
- **BERT**: 事前学習済みトランスフォーマー、高い性能が期待できる
- **DistilBERT**: BERTより軽量

**期待効果**: CV F1が0.85-0.90程度まで向上する可能性

**実装時の注意**:
- 学習時間が非常に長い
- GPUが必要な場合がある
- 過学習に注意

### 4. 予測確率の活用

#### 4.1 閾値調整
**現在**: デフォルトの0.5で分類

**改善案**:
- `predict_proba()`で確率を取得
- 閾値を0.3-0.7の範囲でグリッドサーチ
- F1スコアが最大になる閾値を選択

**期待効果**: CV F1が0.01-0.02程度向上する可能性

#### 4.2 キャリブレーション
**実装案**:
- Platt scaling、Isotonic regressionで確率をキャリブレーション
- より正確な確率推定

### 5. アンサンブル

#### 5.1 モデルアンサンブル
**実装案**:
- 複数のモデル（LogisticRegression、XGBoost、LightGBMなど）を学習
- 予測確率の平均または重み付き平均で最終予測
- Voting、Stacking、Blendingなどの手法

**期待効果**: 個別モデルより0.01-0.03程度向上する可能性

#### 5.2 特徴量セットのアンサンブル
**実装案**:
- textのみ、keywordのみ、text+keywordなど、異なる特徴量セットでモデルを学習
- 予測確率を組み合わせ

### 6. データ拡張・前処理の改善

#### 6.1 テキスト正規化
**実装案**:
- スペルチェック・修正
- 略語の展開（例: "u" → "you"）
- 絵文字の処理

#### 6.2 アンダーサンプリング・オーバーサンプリング
**理由**: クラス不均衡（57% vs 43%）への対応

**実装案**:
- SMOTE、ADASYNなどのオーバーサンプリング
- アンダーサンプリング
- クラス重みの調整（モデル側で対応）

## 実装の優先順位

### 短期（すぐに試せる）
1. **keyword特徴量の追加**（最も効果が期待できる）
2. **ハイパーパラメータチューニング**（LogisticRegressionのC値調整）
3. **閾値調整**（簡単に実装できる）

### 中期（少し時間がかかる）
4. **XGBoost/LightGBMの導入**（非線形モデル）
5. **前処理の効果確認実験**（比較実験）
6. **特徴量の組み合わせ**（text + keyword）

### 長期（時間がかかる）
7. **深層学習モデル**（BERT、LSTMなど）
8. **アンサンブル**（複数モデルの組み合わせ）

## 期待される性能向上

### 現状
- CV F1: 0.7425
- Public LB: 0.80079

### 改善後の目標
- **短期目標**: CV F1 0.78-0.80、Public LB 0.82-0.84
- **中期目標**: CV F1 0.82-0.85、Public LB 0.85-0.87
- **長期目標**: CV F1 0.85-0.90、Public LB 0.88-0.92

## 注意点

1. **過学習への注意**: Train F1とCV F1の差が大きいため、正則化を強化する必要がある可能性
2. **Public LB > CV**: testデータの分布が異なる可能性があるため、CVスコアだけで判断しない
3. **計算リソース**: 深層学習モデルは時間とリソースが必要
4. **再現性**: すべての実験で`random_state=42`を統一

## 関連ノート

- [[project_kaggle_disaster_tweets|プロジェクト: Disaster Tweets]]
- [[task_disaster_tweets_baseline_submit_20260105120020|タスク: ベースライン提出]]
- [[exp20260106030720_report|ベースライン実験レポート]]
- [[disaster_tweets_eda_20260105180000|EDA結果]]




