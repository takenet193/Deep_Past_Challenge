---
id: 20260112174906
title: Disaster Tweets - keyword_tfidf_lr
author: takeikumi
type: experiment_report
experiment_id: exp20260112174906
project: kaggle_disaster_tweets_baseline_improvement
form: report
description: text + keyword + TF-IDF(1-2gram) + LogisticRegression
parent_experiment: exp20260106030720
related_task: task-20260112173705
tags: [kaggle, kaggle_disaster_tweets, improvement, keyword, feature-engineering, tfidf, logistic-regression, nlp, experiment, report]
status: completed
metrics:
  train_f1: 0.8335
  cv_mean: 0.7416
  cv_std: 0.0139
  public_lb: 0.77965
model:
  type: LogisticRegression
  features: [tfidf, keyword_target_encoding]
links:
  - project_kaggle_disaster_tweets_baseline_improvement
  - project_kaggle_disaster_tweets
  - task-20260112173705
  - exp20260106030720_report
  - disaster_tweets_baseline_improvement_ideas_20260112162435
  - disaster_tweets_eda_20260105180000
created: 2026-01-12
updated: 2026-01-12
---

# Disaster Tweets - keyword_tfidf_lr

## 実験概要

| 項目 | 値 |
|:---|:---|
| 実験ID | exp20260112174906（タイムスタンプ形式） |
| 実施日 | 2026-01-12 |
| 目的 | keyword特徴量を追加して性能向上を目指す |
| 親実験 | exp20260106030720（ベースライン） |
| 関連タスク | task-20260112173705 |

## 仮説

- **keyword特徴量の追加**: EDAでkeywordとtargetの相関が非常に強いことが確認されている（`debris`=100%災害、`wreckage`=100%災害など）
- **ターゲットエンコーディング**: keywordをターゲットエンコーディングで数値化し、TF-IDF特徴量と結合
- **期待効果**: CV F1が0.75-0.80程度まで向上する可能性（+0.01-0.04程度）

## 実装内容

### 前処理
- **text前処理**: ベースラインと同じ
  - lowercase: 実施
  - URL除去: 実施
  - メンション除去: 実施
  - ハッシュタグ除去: 実施しない
- **keyword前処理**: 
  - 欠損値処理: "unknown"として新しいカテゴリとして扱う
  - 欠損値数: train=61件（0.8%）、test=26件（0.8%）

### 特徴量エンジニアリング

#### 1. TF-IDF特徴量（ベースラインと同じ）
- max_features: 20000
- ngram_range: (1, 2)
- min_df: 2
- 実際の特徴量数: 16,976

#### 2. keyword特徴量（新規追加）
- **エンコーディング手法**: ターゲットエンコーディング（Target Encoding）
- **実装方法**: 
  - CVの各フォールドで、trainデータ（fold内）のみを使ってkeywordごとの災害率を計算
  - validationデータ（fold外）にエンコーディングを適用（データリークを防止）
  - 平滑化パラメータ: smoothing=1.0（ベイズ推定）
  - 未知のkeyword: 全体平均（trainデータ全体の災害率）で補完
- **keyword数**: 
  - train: 222種類（"unknown"含む）
  - test: 222種類（"unknown"含む）

#### 3. 特徴量の結合
- keyword特徴量（1次元）とTF-IDF特徴量（スパース行列）を`scipy.sparse.hstack`で結合
- 最終特徴量数: 16,977（keyword 1次元 + TF-IDF 16,976次元）

### モデル
- LogisticRegression（ベースラインと同じ）
  - C: 1.0
  - max_iter: 2000
  - random_state: 42

### CV方式
- StratifiedKFold（ベースラインと同じ）
  - n_splits: 5
  - shuffle: True
  - random_state: 42

## ハイパーパラメータ

```yaml
model:
  type: LogisticRegression
  params:
    C: 1.0
    max_iter: 2000
    random_state: 42
seed: 42
cv_folds: 5
feature_engineering:
  type: tfidf_keyword
  params:
    max_features: 20000
    ngram_range: [1, 2]
    min_df: 2
  keyword_encoding:
    method: target_encoding
    missing_value_strategy: unknown
    smoothing: 1.0
```

## 結果

### 評価指標

| Metric | Train | CV Mean | CV Std | Public LB |
|:---|:---:|:---:|:---:|:---:|
| F1 Score | 0.8335 | 0.7416 | 0.0139 | **0.77965** |

### ベースラインとの比較

| Metric | ベースライン | 今回 | 差分 |
|:---|:---:|:---:|:---:|
| Train F1 | 0.8542 | 0.8335 | **-0.0207** |
| CV Mean F1 | 0.7425 | 0.7416 | **-0.0009** |
| CV Std F1 | 0.0137 | 0.0139 | +0.0002 |
| **Public LB F1** | **0.80079** | **0.77965** | **-0.02114** |

### CV詳細（各フォールド）
- Fold 0: 0.7617
- Fold 1: 0.7312
- Fold 2: 0.7237
- Fold 3: 0.7530
- Fold 4: 0.7386

### 予測分布
- 災害予測（target=1）: 1,221件（37.4%）
- 非災害予測（target=0）: 2,042件（62.6%）

## 分析・考察

### 結果の評価

#### ❌ 期待した性能向上は得られなかった
- **CV F1**: ほぼ同等（-0.0009）→ 統計的に有意な差なし
- **Public LB**: **低下**（-0.02114）→ ベースラインより悪化
- **期待値**: CV F1 +0.01-0.04程度の向上を期待していたが、達成できなかった

#### ✅ 良い点
- **過学習の緩和**: Train F1が低下（0.8542 → 0.8335）
  - Train F1とCV F1の差が縮小（0.1117 → 0.0919）
  - より汎化性能が高い可能性
- **CV F1は維持**: 性能低下はほぼない（-0.0009）

### なぜ性能向上しなかったか？

#### 1. keyword情報が既にtextに含まれている可能性
- keywordの内容（例: "debris", "wreckage"）がtext内にも出現している可能性
- TF-IDF特徴量が既にkeywordの情報を捉えている
- 追加したkeyword特徴量が冗長になっている

#### 2. ターゲットエンコーディングの平滑化パラメータ
- smoothing=1.0が適切でなかった可能性
- より強い平滑化（smoothing=5.0, 10.0など）が必要だった可能性
- または平滑化なしの方が良かった可能性

#### 3. keywordとTF-IDF特徴量の相関
- keyword特徴量とTF-IDF特徴量の相関が高い可能性
- 線形モデル（LogisticRegression）では相関の高い特徴量の追加は効果が限定的

#### 4. データリークの可能性（低い）
- CVで適切に実装しているため、データリークは発生していないと判断
- ただし、全データで学習する際のエンコーディング方法に問題があった可能性

### Public LBがCVより低い理由
- **ベースライン**: Public LB (0.80079) > CV (0.7425) → CVが保守的
- **今回**: Public LB (0.77965) < CV (0.7416) → 逆転
- keyword特徴量の追加により、testデータの分布との不一致が生じた可能性

## 学んだこと

1. **EDAで強い相関があっても、特徴量追加が必ずしも性能向上につながるとは限らない**
   - keywordとtargetの相関は強いが、既にtextに含まれている情報だった可能性
   - 特徴量の冗長性を考慮する必要がある

2. **ターゲットエンコーディングの調整が重要**
   - 平滑化パラメータの調整が必要
   - 過学習を防ぐための適切な実装が重要

3. **CVスコアとPublic LBスコアの関係**
   - CVスコアが向上しても、Public LBが向上するとは限らない
   - testデータの分布との一致が重要

4. **過学習の緩和は良い兆候**
   - Train F1とCV F1の差が縮小したのは良い傾向
   - ただし、Public LBが低下しているため、別の問題がある可能性

## 次のステップ

### 短期（すぐに試せる）
1. **ターゲットエンコーディングの平滑化パラメータ調整**
   - smoothing=0.5, 2.0, 5.0, 10.0などで実験
   - 平滑化なし（smoothing=0）も試す

2. **ワンホットエンコーディングの試行**
   - ターゲットエンコーディングではなく、ワンホットエンコーディングを試す
   - keyword数が222種類なので、特徴量数は増えるが試す価値あり

3. **keyword特徴量なしに戻す**
   - ベースラインに戻して、他の改善案（ハイパーパラメータチューニング、閾値調整など）を試す

### 中期
4. **keywordとtextの相互作用特徴量**
   - keywordがtext内に出現するかどうかのバイナリ特徴量
   - keywordの出現位置や頻度

5. **ハイパーパラメータチューニング**
   - LogisticRegressionのC値調整
   - 閾値調整

6. **非線形モデルの導入**
   - XGBoost、LightGBMなど
   - keyword特徴量を直接扱える

### 長期
7. **深層学習モデル**
   - BERT、DistilBERTなど
   - keywordを明示的に扱う

## ファイル一覧

```
experiments/exp20260112174906_keyword_tfidf_lr/
├── exp20260112174906_config.yaml       # 設定ファイル
├── exp20260112174906_train.py          # 学習スクリプト
└── exp20260112174906_predict.py        # 推論スクリプト

results/exp20260112174906_keyword_tfidf_lr/
├── exp20260112174906_report.md         # このファイル（実験レポート）
├── exp20260112174906_metrics.json      # 評価指標
├── exp20260112174906_cv_results.json   # CV結果
├── exp20260112174906_submission.csv    # 提出ファイル
└── exp20260112174906_model.pkl        # モデルファイル
```




