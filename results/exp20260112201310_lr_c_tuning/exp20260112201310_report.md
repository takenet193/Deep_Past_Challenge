---
id: 20260112201310
title: Disaster Tweets - lr_c_tuning_text_only
author: takeikumi
type: experiment_report
experiment_id: exp20260112201310
project: kaggle_disaster_tweets_baseline_improvement
form: report
description: textのみ + TF-IDF + LogisticRegression (C値グリッドサーチ)
parent_experiment: exp20260106030720
related_task: task-20260112182239
tags: [kaggle, kaggle_disaster_tweets, improvement, hyperparameter-tuning, c-tuning, tfidf, logistic-regression, nlp, experiment, report]
status: completed
metrics:
  train_f1: 0.9408
  cv_mean: 0.7469
  cv_std: 0.0100
  public_lb: 0.80202
model:
  type: LogisticRegression
  features: tfidf
  best_C: 5.0
links:
  - project_kaggle_disaster_tweets_baseline_improvement
  - project_kaggle_disaster_tweets
  - task-20260112182239
  - exp20260106030720_report
  - disaster_tweets_baseline_improvement_ideas_20260112162435
created: 2026-01-12
updated: 2026-01-12
---

# Disaster Tweets - lr_c_tuning_text_only

## 実験概要

| 項目 | 値 |
|:---|:---|
| 実験ID | exp20260112201310（タイムスタンプ形式） |
| 実施日 | 2026-01-12 |
| 目的 | LogisticRegressionのC値をチューニングして性能向上を目指す |
| 親実験 | exp20260106030720（ベースライン） |
| 関連タスク | task-20260112182239 |

## 仮説

- **C値の最適化**: ベースラインのC=1.0（デフォルト）から最適なC値を探索することで、CV F1とPublic LBの向上を目指す
- **正則化の調整**: C値を変えることで、過学習と汎化性能のバランスを最適化
- **期待効果**: CV F1が+0.01-0.02程度向上し、0.75-0.77程度まで上がる可能性

## 実装内容

### 前処理
- **text前処理**: ベースラインと同じ
  - lowercase: 実施
  - URL除去: 実施
  - メンション除去: 実施
  - ハッシュタグ除去: 実施しない

### 特徴量エンジニアリング
- **TF-IDF特徴量**（ベースラインと同じ）
  - max_features: 20000
  - ngram_range: (1, 2)
  - min_df: 2
  - 実際の特徴量数: 16,976

### モデル
- **LogisticRegression**
  - C値グリッドサーチ: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
  - max_iter: 2000
  - random_state: 42
  - solver: 'lbfgs'（デフォルト）

### CV方式
- **StratifiedKFold**（ベースラインと同じ）
  - n_splits: 5
  - shuffle: True
  - random_state: 42

### C値スイープ方法
1. 各C値でStratifiedKFoldでCV評価（F1スコア）
2. 各C値で全データで学習し、Train F1を計算
3. CV Mean F1が最大のCを選択（同点の場合はより小さいCを優先）
4. ベストCで最終モデルを学習

## ハイパーパラメータ

```yaml
model:
  type: LogisticRegression
  params:
    C: 5.0           # ベストC（グリッドサーチで決定）
    max_iter: 2000
    random_state: 42
  c_grid: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
seed: 42
cv_folds: 5
```

## 結果

### 評価指標

| Metric | Train | CV Mean | CV Std | Public LB |
|:---|:---:|:---:|:---:|:---:|
| F1 Score | 0.9408 | 0.7469 | 0.0100 | **0.80202** |

### ベースラインとの比較

| Metric | ベースライン | 今回 | 差分 |
|:---|:---:|:---:|:---:|
| **Best C** | 1.0 | **5.0** | - |
| Train F1 | 0.8542 | 0.9408 | **+0.0866** |
| CV Mean F1 | 0.7425 | 0.7469 | **+0.0044** |
| CV Std F1 | 0.0137 | 0.0100 | **-0.0037** |
| **Public LB F1** | **0.80079** | **0.80202** | **+0.00123** |
| Train-CV Gap | 0.1117 | 0.1940 | **+0.0823** |

### C値スイープ結果（全候補）

| C | CV Mean F1 | CV Std | Train F1 | Train-CV Gap |
|:---:|:---:|:---:|:---:|:---:|
| 0.1 | 0.5308 | 0.0120 | 0.6526 | 0.1219 |
| 0.5 | 0.7249 | 0.0111 | 0.8143 | 0.0894 |
| **1.0** | **0.7425** | 0.0137 | 0.8542 | 0.1117 |
| 2.0 | 0.7465 | 0.0119 | 0.8919 | 0.1454 |
| **5.0** | **0.7469** | 0.0100 | 0.9408 | 0.1940 |
| 10.0 | 0.7439 | 0.0070 | 0.9640 | 0.2201 |

### CV詳細（ベストC=5.0、各フォールド）
- Fold 0: 0.7516
- Fold 1: 0.7568
- Fold 2: 0.7282
- Fold 3: 0.7461
- Fold 4: 0.7516

### 予測分布
- 災害予測（target=1）: 1,188件（36.4%）
- 非災害予測（target=0）: 2,075件（63.6%）

## 分析・考察

### 結果の評価

#### ✅ 成功点
1. **Public LBスコアの向上**
   - ベースライン: 0.80079 → 今回: **0.80202**（+0.00123）
   - 目標（ベースライン以上）を達成

2. **CV F1の向上**
   - ベースライン: 0.7425 → 今回: 0.7469（+0.0044）
   - わずかだが向上を確認

3. **CV Stdの改善**
   - ベースライン: 0.0137 → 今回: 0.0100（-0.0037）
   - 予測の安定性が向上

4. **C値の最適化**
   - C=5.0でCV Mean F1が最大（0.7469）
   - C=2.0も候補（CV: 0.7465、過学習: 0.1454）

#### ⚠️ 懸念点
1. **過学習の悪化**
   - Train-CV Gap: 0.1117 → 0.1940（+73.7%増）
   - Train F1: 0.8542 → 0.9408（+0.0866）
   - Cを大きくしすぎた可能性

2. **CV F1の向上幅が小さい**
   - +0.0044は目標下限（+0.005）に届かない
   - 統計的に有意な差かは要検証

### C値の傾向分析

#### C値と性能の関係
- **Cが小さい（0.1, 0.5）**: 正則化が強すぎて性能が低い
- **C=1.0（ベースライン）**: バランスが良いが、CV F1は中程度
- **C=2.0**: CV F1が高く、過学習も比較的少ない（代替候補）
- **C=5.0（ベスト）**: CV F1が最大だが、過学習が大きい
- **C=10.0**: CV F1が低下、過学習がさらに悪化

#### 最適なC値の選択
- **CV Mean F1が最大**: C=5.0（0.7469）
- **過学習が少ない**: C=2.0（Gap=0.1454）
- **バランス**: C=2.0が汎化性能重視なら選択肢

### Public LBが向上した理由
- **CV F1の向上**: わずかだがCV F1が向上（+0.0044）
- **CV Stdの改善**: 予測の安定性が向上（0.0100）
- **C値の最適化**: C=5.0でモデルが最適化された

### 過学習が悪化したにもかかわらずPublic LBが向上した理由
- **CVとPublic LBの関係**: CVが保守的だった可能性
- **testデータの分布**: testデータがtrainデータに近い可能性
- **C値の効果**: C=5.0でモデルがtestデータに適合した可能性

## 学んだこと

1. **C値チューニングの効果**
   - C値を最適化することで、CV F1とPublic LBの両方が向上
   - ただし、過学習が悪化するリスクがある

2. **過学習と汎化性能のバランス**
   - Train-CV Gapが大きくなっても、Public LBが向上する場合がある
   - CVスコアだけで判断せず、Public LBも確認することが重要

3. **C値の選択基準**
   - CV Mean F1が最大のCを選択するのが基本
   - ただし、過学習が大きい場合は、より小さいCを検討する価値がある

4. **CV Stdの重要性**
   - CV Stdが改善（0.0100）することで、予測の安定性が向上
   - これはPublic LB向上に寄与した可能性がある

## 次のステップ

### 短期（すぐに試せる）
1. **C=2.0での再実験**
   - 過学習が少ない（Gap=0.1454）
   - CV F1は-0.0004だが、汎化性能が高い可能性
   - Public LBで比較検証

2. **閾値調整**
   - 予測確率の閾値を調整してF1スコアを最適化
   - 期待効果: CV F1 +0.01-0.02程度

### 中期
3. **solverの変更**
   - 'lbfgs' vs 'liblinear' vs 'saga'の比較
   - C値と組み合わせて最適化

4. **class_weightの調整**
   - `class_weight='balanced'`で不均衡データに対応
   - C値と組み合わせて最適化

5. **非線形モデルの導入**
   - XGBoost、LightGBMなど
   - より高い性能が期待できる

### 長期
6. **深層学習モデル**
   - BERT、DistilBERTなど
   - 期待効果: CV F1 0.85-0.90程度

## ファイル一覧

```
experiments/exp20260112201310_lr_c_tuning/
├── exp20260112201310_config.yaml       # 設定ファイル
├── exp20260112201310_train.py          # 学習スクリプト（C値スイープ機能付き）
└── exp20260112201310_predict.py        # 推論スクリプト

results/exp20260112201310_lr_c_tuning/
├── exp20260112201310_report.md         # このファイル（実験レポート）
├── exp20260112201310_metrics.json      # 評価指標
├── exp20260112201310_cv_results.json   # CV結果（ベストC）
├── exp20260112201310_c_search.json     # C値スイープ結果（全候補）
├── exp20260112201310_submission.csv   # 提出ファイル
└── exp20260112201310_model.pkl        # モデルファイル
```




