---
id: 20260106030720
title: Disaster Tweets - baseline_tfidf_lr_text_only
author: takeikumi
type: experiment_report
experiment_id: exp20260106030720
project: kaggle_disaster_tweets
form: report
description: ベースライン: textのみ + TF-IDF(1-2gram) + LogisticRegression
parent_experiment: null
related_task: task-20260105120020
tags: [kaggle, kaggle_disaster_tweets, baseline, tfidf, logistic-regression, nlp, experiment, report]
status: completed
metrics:
  train_f1: 0.8542
  cv_mean: 0.7425
  cv_std: 0.0137
  public_lb: 0.80079
model:
  type: LogisticRegression
  features: tfidf
links:
  - project_kaggle_disaster_tweets
  - task-20260105120020
  - disaster_tweets_eda_20260105180000
created: 2026-01-06
updated: 2026-01-06
---

# Disaster Tweets - baseline_tfidf_lr_text_only

## 実験概要

| 項目 | 値 |
|:---|:---|
| 実験ID | exp20260106030720（タイムスタンプ形式） |
| 実施日 | 2026-01-06 |
| 目的 | ベースライン: textのみ + TF-IDF(1-2gram) + LogisticRegression |
| 親実験 | なし（初回ベースライン） |
| 関連タスク | task-20260105120020 |

## 仮説

- textのみでシンプルなベースラインを構築し、TF-IDF + LogisticRegressionで基本的な性能を確認する
- EDAで決定した方針（textのみ、TF-IDF(1-2gram), max_features=20000）に従って実装
- 前処理（lowercase、URL除去、メンション除去）の効果を確認

## 実装内容

### 前処理
- lowercase: 実施
- URL除去: 実施（正規表現で除去）
- メンション除去: 実施（`@\w+` パターンで除去）
- ハッシュタグ除去: 実施しない（意味を持つ可能性があるため）

### 特徴量
- TF-IDF（`sklearn.feature_extraction.text.TfidfVectorizer`）
  - max_features: 20000
  - ngram_range: (1, 2)
  - min_df: 2
- 使用列: `text` のみ（`keyword`, `location` は使用しない）

### モデル
- LogisticRegression
  - C: 1.0
  - max_iter: 2000
  - random_state: 42

### CV方式
- StratifiedKFold
  - n_splits: 5
  - shuffle: True
  - random_state: 42 

## ハイパーパラメータ

```yaml
model:
  type: LogisticRegression
  params:
    C: 1.0
    max_iter: 2000
    random_state: 42
seed: 42
cv_folds: 5
feature_engineering:
  type: tfidf
  params:
    max_features: 20000
    ngram_range: [1, 2]
    min_df: 2
```

## 結果

### 評価指標

| Metric | Train | CV Mean | CV Std | Public LB |
|:---|:---:|:---:|:---:|:---:|
| F1 Score | 0.8542 | 0.7425 | 0.0137 | **0.80079** |

### CV詳細（各フォールド）
- Fold 0: 0.7587
- Fold 1: 0.7444
- Fold 2: 0.7178
- Fold 3: 0.7411
- Fold 4: 0.7506

### 特徴量
- TF-IDF特徴量数: 16,976（max_features=20000のうち実際に生成された数）
- 特徴量重要度: LogisticRegressionでは直接取得できないため、省略

## 学んだこと

- シンプルなベースライン（textのみ + TF-IDF + LogisticRegression）でCV F1=0.7425、**Public LB=0.80079**を達成
- **Public LBがCVより高い**（0.80079 vs 0.7425）のは興味深い結果
  - CVが保守的だった可能性、またはtestデータの分布がtrainと異なる可能性
- Train F1=0.8542とCV F1=0.7425の差から、やや過学習の傾向が見られるが、Public LBは良好
- CVスコアの標準偏差が0.0137と比較的小さく、安定している
- 前処理（URL除去、メンション除去）の効果は今後の比較実験で確認が必要

## 次のステップ

- [ ] Kaggleに提出してPublic LBスコアを取得
- [ ] keyword特徴量を追加した実験を実施（EDAで強い相関が確認されている）
- [ ] 前処理の効果を確認するため、URL/メンション除去なしの実験を実施
- [ ] ハイパーパラメータチューニング（C値の調整など）

## ファイル一覧

```
experiments/exp20260106030720_baseline_tfidf_lr/
├── exp20260106030720_config.yaml       # 設定ファイル
├── exp20260106030720_train.py          # 学習スクリプト
└── exp20260106030720_predict.py        # 推論スクリプト

results/exp20260106030720_baseline_tfidf_lr/
├── exp20260106030720_report.md         # このファイル（実験レポート）
├── exp20260106030720_metrics.json      # 評価指標
├── exp20260106030720_cv_results.json    # CV結果
├── exp20260106030720_submission.csv    # 提出ファイル
└── exp20260106030720_model.pkl         # モデルファイル
```


